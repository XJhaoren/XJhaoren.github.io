<!DOCTYPE HTML>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="author" content="Jian Xu">
  <meta name="description" content="Jian Xu's Homepage">
  <meta name="keywords" content="Jian Xu,徐健,homepage,主页,PhD,Large Multimodal Models, AI4Science, Pose Estimation, Image Retrieval">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Jian Xu (徐健)'s Homepage</title>
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jian Xu (徐健)</name>
              </p>
              <p style="text-align:center">
                <span>&#9993;</span> jian.xu@ia.ac.cn &nbsp;
              </p>
              <p style="text-align:left">
                <a href="https://scholar.google.com.hk/citations?user=hqyYoO0AAAAJ&hl=zh-CN"><img src="asserts/google.png" height="40px"></a> &nbsp;&nbsp;
                <a href="https://github.com/XJhaoren"><img src="asserts/github.png" height="40px"></a> &nbsp;&nbsp;
                <!-- <a href="asserts/CV.pdf"><img src="asserts/resume.png" height="40px"></a> &nbsp; -->
              </p>
              <p>I am currently an Associate Professor at Institute of Automation Chinese Academy of Sciences (<a href="http://www.ia.cas.cn/">CASIA</a>) in <a href="https://nlpr.ia.ac.cn/pal/index.html">PAL group</a>.
              </p>
              <p>Before joining CASIA, I have 3 years of experience in AI corporations HUAWEI and XREAL.
              </p>
              <p>
                I obtained my Ph.D. in Pattern Recognition and Intelligent Systems from Institute of Automation, Chinese Academy of Science in 2020, under the supervision of 
                <a href="https://people.ucas.ac.cn/~wangchunheng">Prof. Chunheng Wang</a>. 
                Previously I received my B.S. in Control Science and Engineering from Shandong University in 2015.
              </p>
              <p>
                <!-- I have been focusing on object detection/tracking since I started my PhD in 2015.  -->
                My research interests lie in Large Multimodal Models, AI4Science, Pose Estimation and Image Retrieval.
                </p>
              <p>
                <!-- <strong>
                I'm seeking research interns on 3D human representation. Feel free to send me an email if you are interested.
                </strong> -->
              </p>
		    
            </td>
            <td style="padding:5% 0% 0% 5%;width:40%;max-width:40%">
              <a href="asserts/jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="asserts/protrait.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:0% 0% 0% 0%;width:40%;max-width:40%">
            <a href="asserts/logo.png"><img style="width:100%;max-width:100%" alt="profile photo" src="asserts/logo.png" class="hoverZoomLink"></a>
          </td>
        </tr>
        </tbody></table>
        
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <strong>2023/08/25</strong> &nbsp Had one papers accepted by IEEE Transactions on Image Processing about visual restoration.
              </p><p>
              <p>
                <strong>2023/07/14</strong> &nbsp Had two papers accepted by ICCV 2023 about 3D-aware GAN and face swap.
              </p><p>
              <p>
                <strong>2023/02/28</strong> &nbsp Had one paper accepted by CVPR 2023 about neural hand rendering.
              </p><p>
              <p>
                <strong>2022/07/09</strong> &nbsp Had one paper accepted by ECCV 2022 about open-world object detection.
              </p><p>
              <p>
                <strong>2022/06/30</strong> &nbsp Had one paper accepted by ACM MM 2022 about hand mesh reconstruction.
              </p><p>
                <strong>2022/04/02</strong> &nbsp Our <a href="https://www.amazon.com/Visual-Perception-Control-Underwater-Robots-dp-0367695782/dp/0367695782/ref=mt_other?_encoding=UTF8&me=&qid=">book</a> was <strong>Highly Recommended</strong> by <a href="https://www.choice360.org/products/choice-reviews/">CHOICE Reviews</a>.              
              </p><p>
                <strong>2022/03/02</strong> &nbsp Had one paper accepted by CVPR 2022 about monocular hand reconstruction.              
              </p><p>
                <strong>2022/02/25</strong> &nbsp Had one paper accepted by IEEE Transactions on Cybernetics about few-shot object detection.              
              </p><p>
                <strong>2021/09/01</strong> &nbsp  <a href="https://github.com/SeanChenxy/Hand3DResearch">Hand3DResearch</a> was released to track recent works in 3D hand tasks.              
              </p><p>
                <strong>2021/03/01</strong> &nbsp Had one paper accepted by CVPR 2021 about monocular hand reconstruction.              
              </p>
            </td>
          </tr>
        </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Publications</heading>
<!--             <p>
              (<a href="publication.html">here</a> for full publications)
            </p> -->
          </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


		
	<tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one" >
              <img src='asserts/favor.png' style="width:100%;max-width:100%; position: absolute;top: -5%">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>FAVOR: Full-Body AR-Driven Virtual Object Rearrangement Guided by Instruction Text</papertitle>
              <br>
              <i class="fa fa-envelope"></i>
              Kailin Li, Lixin Yang, Zenan Lin, <strong>Jian Xu</strong>, Xinyu Zhan, Yifei Zhao, Pengxiang Zhu, Wenxiong Kang, Kejian Wu, Cewu Lu
              <br>
              AAAI 2024
              <br>
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28097">[PDF]</a>
              <a href="https://kailinli.github.io/FAVOR/">[Project]</a>
              <br>
              <p>A full-body human motion dataset that captures text-guided desktop object rearrangement through MoCap and AR glasses; & A pipeline for generating avatar's motion of object rearrangement driven by text instruction.</p>
          </td>
        </tr>

	  
	<tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one" >
              <img src='asserts/chord.png' style="width:100%;max-width:100%; position: absolute;top: -5%">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>CHORD: Category-level Hand-held Object Reconstruction via Shape Deformation</papertitle>
              <br>
              <i class="fa fa-envelope"></i>
              Kailin Li, Lixin Yang, Haoyu Zhen, Zenan Lin, Xinyu Zhan, Licheng Zhong, <strong>Jian Xu</strong>, Kejian Wu, Cewu Lu
              <br>
              ICCV 2023
              <br>
              <a href="https://arxiv.org/abs/2308.10574">[PDF]</a>
              <a href="https://kailinli.github.io/CHORD/">[Project]</a>
              <br>
              <p>A single-view hand-held object reconstruction method that exploits the categorical shape prior to reconstruct the shape of intra-class objects; & A new synthetic dataset, COMIC, that contains the category-level collection of objects with diverse shape, materials, interacting poses, and viewing directions.</p>
          </td>
        </tr>
	  

		
        <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one" >
              <img src='asserts/poem.png' style="width:100%;max-width:100%; position: absolute;top: -5%">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>POEM: Reconstructing Hand in a Point Embedded Multi-view Stereo</papertitle>
              <br>
              <i class="fa fa-envelope"></i>
              Lixin Yang, <strong>Jian Xu</strong>, Licheng Zhong, Xinyu Zhan, Zhicheng Wang, Kejian Wu, Cewu Lu
              <br>
              CVPR 2023
              <br>
              <a href="https://arxiv.org/abs/2304.04038">[PDF]</a>
              <a href="https://github.com/lixiny/POEM/">[Project]</a>
              <br>
              <p>We propose a multi-view hand mesh recovery (HMR) method with Transformer. It leverages the "power of points", including Basis Points Set, point's positional encoding and point-Transformer, to unify and merge information from sparsely arranged cameras.</p>
          </td>
        </tr>

        <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one" >
              <img src='asserts/oldnet.png' style="width:100%;max-width:100%; position: absolute;top: -5%">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Object level depth reconstruction for category level 6d object pose estimation from monocular rgb image</papertitle>
              <br>
              Zhaoxin Fan, Zhenbo Song, <strong>Jian Xu</strong>, Zhicheng Wang, Kejian Wu, Hongyan Liu, Jun He
              <br>
              ECCV 2022
              <br>
              <a href="https://arxiv.org/abs/2204.01586">[PDF]</a>
              <a href="https://github.com/FANzhaoxin666/OLD_Net_release">[Project]</a>
              <br>
              <p>We propose to directly predict object-level depth from a monocular RGB image by deforming the category-level shape prior into object-level depth and the canonical NOCS representation.</p>
          </td>
        </tr>

        <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one" >
              <img src='asserts/sba.png' style="width:100%;max-width:100%; position: absolute;top: +5%">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Unsupervised Semantic-Based Aggregation of Deep Convolutional Features</papertitle>
              <br>
              <strong>Jian Xu</strong>, Chunheng Wang, Cunzhao Shi, Baihua Xiao
              <br>
              IEEE Transactions on Image Processing, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/8445607">[PDF]</a>
              <a href="https://github.com/XJhaoren/PWA/">[Project]</a>
              <br>
              <p>We propose a simple but effective semantic-based aggregation (SBA) method. </p>
          </td>
      </tr>

      <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <img src='asserts/ime.png' style="width:100%;max-width:100%; position: absolute;top: -5%">
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Iterative Manifold Embedding Layer Learned by Incomplete Data for Large-Scale Image Retrieval</papertitle>
              <br>
              <strong>Jian Xu</strong>, Chunheng Wang, Chengzuo Qi, Cunzhao Shi, Baihua Xiao
              <br>
              IEEE Transactions on Multimedia, 2019.
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/8566008">[PDF]</a>
              <a href="https://github.com/XJhaoren/IME_layer">[Code]</a>
              <br>
              <p>We propose the iterative manifold embedding (IME) layer, of which the weights are learned offline by an unsupervised strategy, to explore the intrinsic manifolds by incomplete data.</p>
          </td>
      </tr>

      <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                  <img src='asserts/pwa.png' style="width:100%;max-width:100%; position: absolute;top: +5%">
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Unsupervised Part-Based Weighting Aggregation of Deep Convolutional Features for Image Retrieval</papertitle>
              <br>
              <strong>Jian Xu</strong>, Cunzhao Shi, Chengzuo Qi, Chunheng Wang, Baihua Xiao
              <br>
              AAAI 2018
              <br>
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/12231">[PDF]</a>
              <a href="https://github.com/XJhaoren/PWA">[Code]</a>
              <br>
              <p>We propose a simple but effective semantic part-based weighting aggregation (PWA) for image retrieval.</p>
          </td>
      </tr>


	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Research Projects</heading>
          </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
	      <p>[1] 国家自然科学基金重点项目 “基于神经符号系统的数学推理研究”， 2025.1-2029.12， 主要完成人。 </p>
	      <p>[2] 中科院先导 “地空多模态甘蔗表型数据智能分析与优异品种选育”，  2023.10-2028.10，  主要完成人。 </p>
              <p>[3] 北京市科委 “国产化人工智能创新联合体”-科研智能体， 2023.12-2025.12， 主要完成人。 </p>
	      <p>[4] 2035创新任务 “科学大模型构建理论与方法”， 2024.03-2026.03， 主要完成人。 </p>
	      <p>[5] 华为 “时序预测大模型高效微调技术研究”， 2024.05-2025.05，  主要完成人。</p>
	      <p>[6] 深地 “遥感大模型研制与应用开发”， 2023.11-2024.11， 主要完成人。</p>
          </td>
        </tr>

	
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Patents</heading>
          </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
              	  <p>[1] 于杲彤， <strong>徐健</strong>， 王志成， 吴克艰。用于确定手势类型的处理方法、装置、设备和介质， 2022-12-12， 发明专利，  CN202211592961.7。 </p>
	      	  <p>[2] <strong>徐健</strong>， 王志成， 吴克艰。用于虚拟键盘的显示方法和装置，  2022-07-15， 发明专利，  CN202210833540.2。 </p>
		  <p>[3] <strong>徐健</strong>， 王志成， 吴克艰。用于头戴显示设备的控制装置、方法、设备和存储介质， 2022-09-07， 发明专利，  CN202211089235.3。 </p>
		  <p>[4] <strong>徐健</strong>，  张超，  张雅琪， 刘宏马， 贾志平。目标跟踪方法及其装置， 2021-03-29， 发明专利， CN202110336639.7。 </p>
		  <p>[5] <strong>徐健</strong>，  张雅琪， 刘宏马。图像矫正方法、电子设备、介质及片上系统， 2021-09-01， 发明专利， CN202111020078.6。 </p>
		  <p>[6] 张超，  <strong>徐健</strong>， 张雅琪， 刘宏马， 贾志平，  吕帅林。 一种确定跟踪目标的方法及电子设备，  2020-12-29， 发明专利，  CN202011607731.4。 </p>
		  <p>[7] 张雅琪，  张超，  <strong>徐健</strong>，  刘宏马。一种目标跟踪方法及电子设备， 2020-09-30，  发明专利，  CN202011066347.8。 </p>
		  <p>[8] 王春恒，  <strong>徐健</strong>，  肖柏华。 卫星云图分类方法及系统，  2020-06-12，  发明专利，  CN202010024821.4。 </p>
		  <p>[9] 王春恒，  <strong>徐健</strong>，  肖柏华。 图像检索方法及系统， 2020-05-26， 发明专利，  CN202010026336.0。</p>
          </td>
        </tr>
		
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
		<hr style="margin-top:0px">
                <p>The website template was adapted from <a href="https://seanchenxy.github.io//">Xingyu Chen</a>.</p>
            </td>
        </tr>

      </td>
    </tr>
  </table>
</body>

</html>
